{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-01-header",
   "metadata": {},
   "source": [
    "# BSAD 8310: Business Forecasting\n",
    "## Lab 01 — Introduction to Forecasting\n",
    "**University of Nebraska at Omaha**\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Load and visualize a real-world business time series\n",
    "2. Decompose a series into trend, seasonal, and residual components\n",
    "3. Implement four benchmark forecasting models in Python\n",
    "4. Evaluate forecast accuracy using RMSE, MAE, and MAPE\n",
    "5. Produce a publication-ready comparison plot\n",
    "\n",
    "### Dataset\n",
    "\n",
    "**US Advance Monthly Retail Trade Survey — Total Retail Sales (RSXFS)**  \n",
    "Source: Federal Reserve Bank of St. Louis (FRED)  \n",
    "Frequency: Monthly  \n",
    "Units: Millions of dollars, seasonally unadjusted  \n",
    "\n",
    "We use the **not seasonally adjusted** series so that seasonality is visible.  \n",
    "If FRED access is unavailable, a fallback dataset is provided automatically.\n",
    "\n",
    "### Notation (matches Lecture 1 slides)\n",
    "\n",
    "| Symbol | Python variable | Meaning |\n",
    "|--------|----------------|---------|\n",
    "| $y_t$ | `y` | Time series observation |\n",
    "| $\\hat{y}_{t+h\\|t}$ | `y_hat` | Point forecast |\n",
    "| $e_t$ | `e` | Forecast error = $y_t - \\hat{y}_{t\\|t-1}$ |\n",
    "| $m$ | `m` | Seasonal period (12 for monthly) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-02-imports-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Statsmodels\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---- UNO Maverick color palette ----\n",
    "UNO_BLUE  = '#005CA9'\n",
    "UNO_RED   = '#E41C38'\n",
    "GRAY      = '#525252'\n",
    "GREEN     = '#15803d'\n",
    "LIGHT_BLUE = '#E8F0FA'\n",
    "\n",
    "# ---- Matplotlib defaults ----\n",
    "mpl.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.titlecolor': UNO_BLUE,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'legend.frameon': False,\n",
    "    'figure.dpi': 150,\n",
    "    'lines.linewidth': 1.8,\n",
    "})\n",
    "\n",
    "# ---- Paths ----\n",
    "ROOT = Path('.').resolve().parent  # repo root (one level above scripts/)\n",
    "FIG_DIR = ROOT / 'Figures'\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Setup complete.')\n",
    "print(f'Figures will be saved to: {FIG_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04-data-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Load and Explore the Data\n",
    "\n",
    "We attempt to load US Retail Sales (RSXFS) from FRED.  \n",
    "If unavailable, we fall back to the classic **US Air Passenger** dataset,\n",
    "which has the same structural features (trend + strong seasonality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-05-load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Load data: FRED RSXFS or fallback ----\n",
    "m = 12  # seasonal period (monthly data)\n",
    "\n",
    "try:\n",
    "    import pandas_datareader.data as web\n",
    "    import datetime\n",
    "\n",
    "    start = datetime.datetime(2000, 1, 1)\n",
    "    end   = datetime.datetime(2023, 12, 1)\n",
    "\n",
    "    raw = web.DataReader('RSXFS', 'fred', start, end)\n",
    "    y = raw['RSXFS'].dropna()\n",
    "    series_name = 'US Retail Sales (RSXFS, millions USD)'\n",
    "    print(f'Loaded FRED data: {len(y)} monthly observations.')\n",
    "\n",
    "except Exception as exc:\n",
    "    # Fallback: AirPassengers dataset from statsmodels\n",
    "    import statsmodels.api as sm\n",
    "    air = sm.datasets.get_rdataset('AirPassengers', 'datasets').data\n",
    "    # Convert to monthly DatetimeIndex\n",
    "    y = pd.Series(\n",
    "        air['value'].values,\n",
    "        index=pd.date_range('1949-01', periods=len(air), freq='MS'),\n",
    "        name='Passengers'\n",
    "    )\n",
    "    series_name = 'Monthly Airline Passengers (thousands)'\n",
    "    print(f'FRED unavailable ({exc.__class__.__name__}). '\n",
    "          f'Using AirPassengers fallback: {len(y)} observations.')\n",
    "\n",
    "# Summary\n",
    "print(f'\\nSeries: {series_name}')\n",
    "print(f'Start:  {y.index[0].strftime(\"%Y-%m\")}')\n",
    "print(f'End:    {y.index[-1].strftime(\"%Y-%m\")}')\n",
    "print(f'Mean:   {y.mean():.1f}  |  Std: {y.std():.1f}')\n",
    "print(f'Min:    {y.min():.1f}  |  Max: {y.max():.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-06-plot-raw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plot the raw time series ----\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "ax.plot(y.index, y.values, color=UNO_BLUE, linewidth=1.5, label=series_name)\n",
    "ax.set_title('Raw Time Series', fontsize=14, fontweight='bold', color=UNO_BLUE)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Value')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIG_DIR / 'lecture01_raw_series.png', dpi=150, bbox_inches='tight',\n",
    "            facecolor='white')\n",
    "plt.show()\n",
    "print('Figure saved: lecture01_raw_series.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-07-decomp-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: STL Decomposition\n",
    "\n",
    "**STL** (Seasonal-Trend decomposition using LOESS) decomposes $y_t$ into:\n",
    "$$y_t = T_t + S_t + R_t$$\n",
    "where $T_t$ is the trend, $S_t$ is the seasonal component, and $R_t$ is the remainder.\n",
    "\n",
    "This gives us a visual intuition for what a good forecast model must capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-08-stl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- STL decomposition ----\n",
    "stl = STL(y, period=m, robust=True)\n",
    "result = stl.fit()\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "components = [\n",
    "    (y.values,             'Observed $y_t$',    UNO_BLUE),\n",
    "    (result.trend,         'Trend $T_t$',        UNO_BLUE),\n",
    "    (result.seasonal,      'Seasonal $S_t$',     UNO_RED),\n",
    "    (result.resid,         'Remainder $R_t$',    GRAY),\n",
    "]\n",
    "\n",
    "for ax, (data, label, color) in zip(axes, components):\n",
    "    ax.plot(y.index, data, color=color, linewidth=1.5)\n",
    "    ax.set_ylabel(label, fontsize=10)\n",
    "    ax.axhline(0, color=GRAY, linewidth=0.5, linestyle='--')\n",
    "\n",
    "axes[0].set_title('STL Decomposition', fontsize=14, fontweight='bold', color=UNO_BLUE)\n",
    "axes[-1].set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIG_DIR / 'lecture01_stl_decomposition.png', dpi=150,\n",
    "            bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print('Figure saved: lecture01_stl_decomposition.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-09-split-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Train / Test Split\n",
    "\n",
    "We hold out the **last 24 months** as a test set.  \n",
    "All models are trained on the remaining history.\n",
    "\n",
    "> **Key rule:** Time order is never violated. We never randomly shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Train/test split ----\n",
    "H = 24  # forecast horizon (months)\n",
    "\n",
    "y_train = y.iloc[:-H]\n",
    "y_test  = y.iloc[-H:]\n",
    "\n",
    "print(f'Training set: {y_train.index[0].strftime(\"%Y-%m\")} to '\n",
    "      f'{y_train.index[-1].strftime(\"%Y-%m\")}  ({len(y_train)} obs)')\n",
    "print(f'Test set:     {y_test.index[0].strftime(\"%Y-%m\")} to '\n",
    "      f'{y_test.index[-1].strftime(\"%Y-%m\")}  ({len(y_test)} obs, H={H})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11-benchmarks-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Implement Benchmark Forecasts\n",
    "\n",
    "We implement the four benchmarks from Lecture 1:\n",
    "\n",
    "| Model | Formula | Python |\n",
    "|-------|---------|--------|\n",
    "| Naïve | $\\hat{y}_{t+h\\|t} = y_t$ | Last train value |\n",
    "| Seasonal Naïve | $\\hat{y}_{t+h\\|t} = y_{t+h-m}$ | Shift by 12 |\n",
    "| Historical Mean | $\\hat{y}_{t+h\\|t} = \\bar{y}$ | `y_train.mean()` |\n",
    "| RW with Drift | $\\hat{y}_{t+h\\|t} = y_t + h\\hat{c}$ | Linear extrapolation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12-benchmarks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Benchmark 1: Naïve forecast ----\n",
    "last_value = y_train.iloc[-1]\n",
    "y_hat_naive = pd.Series(\n",
    "    np.full(H, last_value),\n",
    "    index=y_test.index\n",
    ")\n",
    "\n",
    "# ---- Benchmark 2: Seasonal Naïve ----\n",
    "# Use the last m observations from train as the seasonal pattern\n",
    "last_season = y_train.iloc[-m:].values   # shape (12,)\n",
    "# Tile to cover H periods\n",
    "reps = int(np.ceil(H / m))\n",
    "seasonal_pattern = np.tile(last_season, reps)[:H]\n",
    "y_hat_snaive = pd.Series(seasonal_pattern, index=y_test.index)\n",
    "\n",
    "# ---- Benchmark 3: Historical Mean ----\n",
    "mean_value = y_train.mean()\n",
    "y_hat_mean = pd.Series(\n",
    "    np.full(H, mean_value),\n",
    "    index=y_test.index\n",
    ")\n",
    "\n",
    "# ---- Benchmark 4: Random Walk with Drift ----\n",
    "# Drift = average period-to-period change over training set\n",
    "drift = (y_train.iloc[-1] - y_train.iloc[0]) / (len(y_train) - 1)\n",
    "y_hat_drift = pd.Series(\n",
    "    [last_value + (h + 1) * drift for h in range(H)],\n",
    "    index=y_test.index\n",
    ")\n",
    "\n",
    "print('Benchmark forecasts computed.')\n",
    "print(f'  Naïve:          {y_hat_naive.iloc[0]:.1f} (flat)')\n",
    "print(f'  Seasonal Naïve: {y_hat_snaive.iloc[:3].values}  ... (seasonal pattern)')\n",
    "print(f'  Mean:           {y_hat_mean.iloc[0]:.1f} (flat)')\n",
    "print(f'  Drift:          {y_hat_drift.iloc[0]:.1f} → {y_hat_drift.iloc[-1]:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13-eval-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Evaluate Forecast Accuracy\n",
    "\n",
    "Compute RMSE, MAE, and MAPE for each benchmark on the test set.\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{H}\\sum_{h=1}^{H}(y_{T+h} - \\hat{y}_{T+h|T})^2}\n",
    "\\qquad\n",
    "\\text{MAE} = \\frac{1}{H}\\sum_{h=1}^{H}|y_{T+h} - \\hat{y}_{T+h|T}|\n",
    "\\qquad\n",
    "\\text{MAPE} = \\frac{1}{H}\\sum_{h=1}^{H}\\left|\\frac{e_{T+h}}{y_{T+h}}\\right| \\times 100\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_actual: pd.Series, y_forecast: pd.Series) -> dict:\n",
    "    \"\"\"Compute RMSE, MAE, and MAPE for point forecasts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_actual : pd.Series\n",
    "        Realized values (the test set).\n",
    "    y_forecast : pd.Series\n",
    "        Point forecasts aligned to y_actual.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys 'RMSE', 'MAE', 'MAPE'.\n",
    "    \"\"\"\n",
    "    e = y_actual.values - y_forecast.values  # forecast errors e_t = y_t - y_hat\n",
    "    rmse = np.sqrt(np.mean(e ** 2))\n",
    "    mae  = np.mean(np.abs(e))\n",
    "    mape = np.mean(np.abs(e / y_actual.values)) * 100\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape}\n",
    "\n",
    "\n",
    "# ---- Compute metrics for all four benchmarks ----\n",
    "benchmarks = {\n",
    "    'Naïve':           y_hat_naive,\n",
    "    'Seasonal Naïve':  y_hat_snaive,\n",
    "    'Historical Mean': y_hat_mean,\n",
    "    'RW + Drift':      y_hat_drift,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, y_hat in benchmarks.items():\n",
    "    results[name] = compute_metrics(y_test, y_hat)\n",
    "\n",
    "# ---- Display as a formatted table ----\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df[['RMSE', 'MAE', 'MAPE']].round(2)\n",
    "results_df['MAPE'] = results_df['MAPE'].apply(lambda x: f'{x:.2f}%')\n",
    "\n",
    "print('\\n=== Forecast Accuracy: 24-Month Out-of-Sample ===')\n",
    "print(results_df.to_string())\n",
    "print('\\nLower is better for all metrics.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15-plot-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Visualization — Actual vs. Forecasts\n",
    "\n",
    "A publication-ready comparison plot using the UNO color palette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16-plot-forecasts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Publication-ready forecast comparison plot ----\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "# Show last 36 months of training + all test\n",
    "n_context = 36\n",
    "y_context = y_train.iloc[-n_context:]\n",
    "\n",
    "# Plot training context\n",
    "ax.plot(y_context.index, y_context.values,\n",
    "        color=GRAY, linewidth=1.5, label='History (last 3 years)', alpha=0.7)\n",
    "\n",
    "# Plot actual test values\n",
    "ax.plot(y_test.index, y_test.values,\n",
    "        color='black', linewidth=2.0, label='Actual (test set)', zorder=5)\n",
    "\n",
    "# Plot each benchmark\n",
    "colors = [UNO_BLUE, UNO_RED, GREEN, '#FF8C00']\n",
    "linestyles = ['--', '--', ':', '-.']\n",
    "for (name, y_hat), color, ls in zip(benchmarks.items(), colors, linestyles):\n",
    "    ax.plot(y_hat.index, y_hat.values,\n",
    "            color=color, linewidth=1.5, linestyle=ls, label=name)\n",
    "\n",
    "# Vertical line at forecast origin\n",
    "ax.axvline(y_test.index[0], color=UNO_RED, linewidth=1.0,\n",
    "           linestyle=':', alpha=0.6, label='Forecast origin')\n",
    "\n",
    "# Shading for test period\n",
    "ax.axvspan(y_test.index[0], y_test.index[-1],\n",
    "           alpha=0.05, color=UNO_RED)\n",
    "\n",
    "ax.set_title('Benchmark Forecasts vs. Actual', fontsize=14,\n",
    "             fontweight='bold', color=UNO_BLUE)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Value')\n",
    "ax.legend(loc='upper left', fontsize=9, ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIG_DIR / 'lecture01_benchmark_forecasts.png',\n",
    "            dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print('Figure saved: lecture01_benchmark_forecasts.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17-accuracy-bar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Bar chart: RMSE comparison ----\n",
    "rmse_values = {name: compute_metrics(y_test, y_hat)['RMSE']\n",
    "               for name, y_hat in benchmarks.items()}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "bar_colors = [UNO_BLUE if v == min(rmse_values.values()) else GRAY\n",
    "              for v in rmse_values.values()]\n",
    "\n",
    "bars = ax.bar(rmse_values.keys(), rmse_values.values(),\n",
    "              color=bar_colors, edgecolor='white', linewidth=0.5)\n",
    "\n",
    "# Label each bar\n",
    "for bar, val in zip(bars, rmse_values.values()):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() + max(rmse_values.values()) * 0.01,\n",
    "            f'{val:.0f}', ha='center', va='bottom', fontsize=10, color=GRAY)\n",
    "\n",
    "ax.set_title('RMSE by Benchmark Model (lower is better)',\n",
    "             fontsize=14, fontweight='bold', color=UNO_BLUE)\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_ylim(0, max(rmse_values.values()) * 1.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIG_DIR / 'lecture01_rmse_comparison.png',\n",
    "            dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print('Figure saved: lecture01_rmse_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18-discussion",
   "metadata": {},
   "source": [
    "---\n",
    "## Discussion Questions\n",
    "\n",
    "Answer these questions based on your results above.\n",
    "\n",
    "1. Which benchmark performed best on RMSE? On MAPE? Are they the same model?\n",
    "\n",
    "2. The Seasonal Naïve model does not account for trend. How does this limitation show up visually in the forecast plot?\n",
    "\n",
    "3. The Historical Mean benchmark uses all available training data equally. Is this always a good idea for a series with trend?\n",
    "\n",
    "4. Look at the RMSE bar chart. By how much (in percentage) does the best benchmark beat the worst? Is this a large or small difference in practical terms?\n",
    "\n",
    "5. **Challenge:** The benchmark principle says a useful model must beat the best benchmark. Based on what you see in the decomposition plot, what features would a better model need to capture?\n",
    "\n",
    "---\n",
    "## Summary\n",
    "\n",
    "In this lab we:\n",
    "\n",
    "- Loaded and explored a real business time series with trend and seasonality\n",
    "- Used STL to decompose the series into interpretable components\n",
    "- Implemented four standard benchmarks: Naïve, Seasonal Naïve, Mean, RW+Drift\n",
    "- Evaluated accuracy using RMSE, MAE, and MAPE on a held-out test set\n",
    "- Produced publication-ready visualizations\n",
    "\n",
    "**Next lecture:** Regression-Based Forecasting — using predictor variables to improve on these benchmarks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

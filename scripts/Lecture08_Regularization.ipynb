{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 08: Regularization — LASSO, Ridge, and Elastic Net\n",
    "\n",
    "**BSAD 8310: Business Forecasting | University of Nebraska at Omaha**\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Build a lag-feature matrix for RSXFS retail sales\n",
    "2. Fit Ridge, LASSO, and Elastic Net regressions with a leakage-free `sklearn` Pipeline\n",
    "3. Tune `λ` via `TimeSeriesSplit` cross-validation\n",
    "4. Visualise Ridge and LASSO coefficient paths\n",
    "5. Compare regularised forecasts against the SARIMA baseline\n",
    "\n",
    "## Packages Required\n",
    "```\n",
    "numpy, pandas, matplotlib, scikit-learn, statsmodels\n",
    "pandas_datareader (optional — FRED data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Section 1: Setup\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import (\n",
    "    Ridge, Lasso, ElasticNet,\n",
    "    RidgeCV, LassoCV, ElasticNetCV,\n",
    "    lasso_path\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# UNO color palette\n",
    "UNO = {\n",
    "    'blue':       '#005CA9',\n",
    "    'red':        '#E41C38',\n",
    "    'gray':       '#525252',\n",
    "    'green':      '#15803d',\n",
    "    'lightblue':  '#cce0f5',\n",
    "    'lightred':   '#fde8eb',\n",
    "    'lightgreen': '#dcfce7',\n",
    "    'lightgray':  '#e5e5e5',\n",
    "}\n",
    "\n",
    "# Publication-ready plot defaults\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi':       150,\n",
    "    'axes.spines.top':  False,\n",
    "    'axes.spines.right':False,\n",
    "    'font.size':        11,\n",
    "    'axes.titlesize':   13,\n",
    "    'axes.labelsize':   11,\n",
    "})\n",
    "\n",
    "FIGURE_DIR = '../Figures'\n",
    "import os; os.makedirs(FIGURE_DIR, exist_ok=True)\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Section 2: Load Data\n",
    "# =============================================================================\n",
    "# Primary: US Monthly Retail Sales (RSXFS) from FRED\n",
    "# Fallback: statsmodels macrodata (quarterly — will be resampled)\n",
    "\n",
    "try:\n",
    "    import pandas_datareader.data as web\n",
    "    from datetime import datetime\n",
    "    raw = web.DataReader('RSXFS', 'fred',\n",
    "                         start='1992-01-01',\n",
    "                         end='2024-12-01')\n",
    "    y_all = raw['RSXFS'].dropna()\n",
    "    y_all.index = pd.to_datetime(y_all.index).to_period('M')\n",
    "    data_source = 'FRED RSXFS'\n",
    "    print(f'Loaded FRED RSXFS: {len(y_all)} monthly observations')\n",
    "except Exception:\n",
    "    import statsmodels.api as sm\n",
    "    macro = sm.datasets.macrodata.load_pandas().data\n",
    "    macro.index = pd.period_range('1959Q1', periods=len(macro), freq='Q')\n",
    "    y_all = macro['realgdp']\n",
    "    data_source = 'Macrodata (realgdp, quarterly fallback)'\n",
    "    print(f'Loaded statsmodels macrodata: {len(y_all)} quarters (fallback)')\n",
    "\n",
    "print(f'Source: {data_source}')\n",
    "print(f'Range:  {y_all.index[0]} to {y_all.index[-1]}')\n",
    "y_all.plot(title='RSXFS: US Retail Sales', color=UNO['blue'],\n",
    "           ylabel='Millions USD', figsize=(10, 3))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Section 3: Feature Engineering\n",
    "# =============================================================================\n",
    "# Build lag features BEFORE rolling windows to prevent leakage:\n",
    "# Rolling stats must use .shift(1) first so they don't see y_t.\n",
    "\n",
    "def make_features(y, n_lags=12, roll_windows=(3, 6, 12), add_calendar=True):\n",
    "    \"\"\"\n",
    "    Construct a supervised feature matrix from a univariate time series.\n",
    "\n",
    "    Leakage prevention:\n",
    "    - All lag features use .shift(k) so lag k = y_{t-k}\n",
    "    - Rolling stats are computed on the lagged series (.shift(1))\n",
    "      so they only see y_{t-1}, y_{t-2}, ...\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : pd.DataFrame  Feature matrix (aligned, NaN rows dropped)\n",
    "    y_aligned : pd.Series  Target aligned with X\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'y': y})\n",
    "\n",
    "    # Lag features: y_{t-1}, ..., y_{t-n_lags}\n",
    "    for k in range(1, n_lags + 1):\n",
    "        df[f'lag_{k}'] = y.shift(k)\n",
    "\n",
    "    # Rolling stats on y_{t-1} to prevent leakage\n",
    "    y_lagged = y.shift(1)\n",
    "    for w in roll_windows:\n",
    "        df[f'roll_mean_{w}'] = y_lagged.rolling(w).mean()\n",
    "        df[f'roll_std_{w}']  = y_lagged.rolling(w).std()\n",
    "\n",
    "    # Calendar dummies (month-of-year, 11 dummies — Jan is baseline)\n",
    "    if add_calendar:\n",
    "        if hasattr(y.index, 'month'):\n",
    "            month = y.index.month\n",
    "        elif hasattr(y.index, 'to_timestamp'):\n",
    "            month = y.index.to_timestamp().month\n",
    "        else:\n",
    "            month = None\n",
    "        if month is not None:\n",
    "            for m in range(2, 13):\n",
    "                df[f'month_{m}'] = (month == m).astype(int)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    X = df.drop(columns=['y'])\n",
    "    y_aligned = df['y']\n",
    "    return X, y_aligned\n",
    "\n",
    "\n",
    "X, y = make_features(y_all, n_lags=12, roll_windows=(3, 6, 12))\n",
    "print(f'Feature matrix shape: {X.shape}')\n",
    "print(f'Features: {list(X.columns)}')\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Section 4: Three-Way Chronological Split\n",
    "# =============================================================================\n",
    "# Split: 70% train | 15% validation | 15% test\n",
    "# No random shuffling — time ordering must be preserved.\n",
    "\n",
    "n = len(y)\n",
    "n_test = int(0.15 * n)\n",
    "n_val  = int(0.15 * n)\n",
    "n_train = n - n_val - n_test\n",
    "\n",
    "X_train = X.iloc[:n_train]\n",
    "y_train = y.iloc[:n_train]\n",
    "\n",
    "X_val   = X.iloc[n_train:n_train+n_val]\n",
    "y_val   = y.iloc[n_train:n_train+n_val]\n",
    "\n",
    "X_test  = X.iloc[n_train+n_val:]\n",
    "y_test  = y.iloc[n_train+n_val:]\n",
    "\n",
    "# Train+val combined for final refit after CV\n",
    "X_trainval = X.iloc[:n_train+n_val]\n",
    "y_trainval = y.iloc[:n_train+n_val]\n",
    "\n",
    "print(f'Train:    {X_train.shape[0]} obs  ({y_train.index[0]} – {y_train.index[-1]})')\n",
    "print(f'Val:      {X_val.shape[0]} obs  ({y_val.index[0]} – {y_val.index[-1]})')\n",
    "print(f'Test:     {X_test.shape[0]} obs  ({y_test.index[0]} – {y_test.index[-1]})')\n",
    "\n",
    "# Visualise the split\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.plot(y_train.index.astype(str), y_train.values,\n",
    "        color=UNO['blue'],  lw=1.5, label='Train')\n",
    "ax.plot(y_val.index.astype(str),   y_val.values,\n",
    "        color=UNO['green'], lw=1.5, label='Validation')\n",
    "ax.plot(y_test.index.astype(str),  y_test.values,\n",
    "        color=UNO['red'],   lw=1.5, label='Test')\n",
    "ax.set_title('Three-Way Chronological Split')\n",
    "ax.set_xlabel('Period')\n",
    "ax.legend()\n",
    "ax.xaxis.set_major_locator(mticker.MaxNLocator(8))\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Section 5: Ridge and LASSO — Validation Curve\n",
    "# =============================================================================\n",
    "# Use GridSearchCV with TimeSeriesSplit to select optimal alpha (= lambda).\n",
    "# StandardScaler is INSIDE the Pipeline — no leakage.\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5, gap=0)\n",
    "alpha_grid = np.logspace(-3, 4, 80)\n",
    "\n",
    "def fit_regularised(model_class, X_tr, y_tr, alpha_grid, tscv):\n",
    "    \"\"\"Fit regularised model via GridSearchCV; return best estimator + CV results.\"\"\"\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model',  model_class())\n",
    "    ])\n",
    "    gs = GridSearchCV(\n",
    "        pipe,\n",
    "        {'model__alpha': alpha_grid},\n",
    "        cv=tscv,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        refit=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    gs.fit(X_tr, y_tr)\n",
    "    return gs\n",
    "\n",
    "print('Fitting Ridge via TimeSeriesSplit CV...')\n",
    "gs_ridge = fit_regularised(Ridge, X_trainval, y_trainval, alpha_grid, tscv)\n",
    "print(f'  Ridge best alpha: {gs_ridge.best_params_[\"model__alpha\"]:.4f}')\n",
    "\n",
    "print('Fitting LASSO via TimeSeriesSplit CV...')\n",
    "gs_lasso = fit_regularised(Lasso, X_trainval, y_trainval, alpha_grid, tscv)\n",
    "print(f'  LASSO best alpha: {gs_lasso.best_params_[\"model__alpha\"]:.4f}')\n",
    "\n",
    "# Plot validation curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "for ax, gs, title, color in zip(\n",
    "    axes,\n",
    "    [gs_ridge, gs_lasso],\n",
    "    ['Ridge', 'LASSO'],\n",
    "    [UNO['blue'], UNO['red']]\n",
    "):\n",
    "    results = gs.cv_results_\n",
    "    alphas  = results['param_model__alpha'].astype(float)\n",
    "    val_rmse  = -results['mean_test_score']\n",
    "    best_alpha = gs.best_params_['model__alpha']\n",
    "\n",
    "    ax.semilogx(alphas, val_rmse, color=color, lw=2, label='Val RMSE')\n",
    "    ax.axvline(best_alpha, color='black', ls='--', lw=1.2,\n",
    "               label=f'λ* = {best_alpha:.3f}')\n",
    "    ax.set_title(f'{title}: Validation Curve')\n",
    "    ax.set_xlabel('α (= λ)')\n",
    "    ax.set_ylabel('RMSE')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{FIGURE_DIR}/lecture08_validation_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved lecture08_validation_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Section 6: Coefficient Paths\n",
    "# =============================================================================\n",
    "# Ridge path: refit at each alpha on train+val (scaled once for illustration)\n",
    "# LASSO path: use sklearn's lasso_path (coordinate descent, warm starts)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tv_sc = scaler.fit_transform(X_trainval)\n",
    "\n",
    "alpha_path = np.logspace(-2, 4, 60)\n",
    "\n",
    "# Ridge coefficient path\n",
    "ridge_coefs = np.array([\n",
    "    Ridge(alpha=a).fit(X_tv_sc, y_trainval).coef_\n",
    "    for a in alpha_path\n",
    "])\n",
    "\n",
    "# LASSO coefficient path (lasso_path returns alphas, coefs, gaps)\n",
    "lasso_alphas, lasso_coefs, _ = lasso_path(\n",
    "    X_tv_sc, y_trainval,\n",
    "    alphas=alpha_path[::-1],  # lasso_path expects decreasing alphas\n",
    "    max_iter=5000\n",
    ")\n",
    "\n",
    "feat_names = X_trainval.columns.tolist()\n",
    "n_show = min(8, len(feat_names))   # show first 8 features for clarity\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4.5))\n",
    "\n",
    "# Ridge path\n",
    "ax = axes[0]\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, n_show))\n",
    "for i in range(n_show):\n",
    "    ax.semilogx(alpha_path, ridge_coefs[:, i],\n",
    "                color=colors[i], lw=1.5, label=feat_names[i])\n",
    "ax.axvline(gs_ridge.best_params_['model__alpha'],\n",
    "           color='black', ls='--', lw=1.2, label='λ*')\n",
    "ax.axhline(0, color='gray', lw=0.8, ls=':')\n",
    "ax.set_title('Ridge: Coefficient Path')\n",
    "ax.set_xlabel('α (= λ)')\n",
    "ax.set_ylabel('Standardised coefficient')\n",
    "ax.legend(fontsize=7, ncol=2, loc='upper right')\n",
    "\n",
    "# LASSO path\n",
    "ax = axes[1]\n",
    "for i in range(n_show):\n",
    "    ax.semilogx(lasso_alphas, lasso_coefs[i, :],\n",
    "                color=colors[i], lw=1.5, label=feat_names[i])\n",
    "ax.axvline(gs_lasso.best_params_['model__alpha'],\n",
    "           color='black', ls='--', lw=1.2, label='λ*')\n",
    "ax.axhline(0, color='gray', lw=0.8, ls=':')\n",
    "ax.set_title('LASSO: Coefficient Path')\n",
    "ax.set_xlabel('α (= λ)')\n",
    "ax.set_ylabel('Standardised coefficient')\n",
    "ax.legend(fontsize=7, ncol=2, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{FIGURE_DIR}/lecture08_ridge_path.png', dpi=150, bbox_inches='tight')\n",
    "plt.savefig(f'{FIGURE_DIR}/lecture08_lasso_path.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved lecture08_ridge_path.png and lecture08_lasso_path.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Section 7: Elastic Net\n",
    "# =============================================================================\n",
    "# Try three mix ratios (l1_ratio = alpha in sklearn ElasticNet notation).\n",
    "# Then select best via TimeSeriesSplit CV.\n",
    "\n",
    "# Note: sklearn ElasticNet uses l1_ratio (= our alpha) and alpha (= our lambda)\n",
    "en_param_grid = {\n",
    "    'model__alpha':    np.logspace(-3, 4, 40),\n",
    "    'model__l1_ratio': [0.1, 0.5, 0.9],\n",
    "}\n",
    "\n",
    "en_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model',  ElasticNet(max_iter=5000))\n",
    "])\n",
    "\n",
    "print('Fitting Elastic Net via GridSearchCV (alpha x l1_ratio grid)...')\n",
    "gs_en = GridSearchCV(\n",
    "    en_pipe, en_param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    refit=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "gs_en.fit(X_trainval, y_trainval)\n",
    "\n",
    "best = gs_en.best_params_\n",
    "print(f'  Best lambda (alpha):   {best[\"model__alpha\"]:.4f}')\n",
    "print(f'  Best mix   (l1_ratio): {best[\"model__l1_ratio\"]}')\n",
    "\n",
    "# Count non-zero coefficients at best settings\n",
    "en_coef = gs_en.best_estimator_.named_steps['model'].coef_\n",
    "n_active = np.sum(en_coef != 0)\n",
    "print(f'  Active features: {n_active} / {X_trainval.shape[1]}')\n",
    "\n",
    "# Bar chart of coefficients\n",
    "coef_df = pd.Series(en_coef, index=feat_names).sort_values()\n",
    "fig, ax = plt.subplots(figsize=(8, max(4, n_active * 0.3 + 1)))\n",
    "coef_df[coef_df != 0].plot.barh(\n",
    "    ax=ax, color=UNO['blue'], edgecolor='white'\n",
    ")\n",
    "ax.axvline(0, color='black', lw=0.8)\n",
    "ax.set_title(f'Elastic Net Coefficients (λ={best[\"model__alpha\"]:.3f}, '\n",
    "             f'l1_ratio={best[\"model__l1_ratio\"]})')\n",
    "ax.set_xlabel('Standardised coefficient')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Section 8: SARIMA Baseline\n",
    "# =============================================================================\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Fit SARIMA(1,1,1)(1,1,1)_12 on train+val; forecast test period\n",
    "# Use train period only for fitting (consistent with regularised models)\n",
    "try:\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "    sarima_mod = SARIMAX(\n",
    "        y_trainval,\n",
    "        order=(1, 1, 1),\n",
    "        seasonal_order=(1, 1, 1, 12),\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    sarima_res = sarima_mod.fit(disp=False)\n",
    "    y_pred_sarima = sarima_res.forecast(len(y_test))\n",
    "    sarima_ok = True\n",
    "    print('SARIMA fit complete.')\n",
    "except Exception as e:\n",
    "    print(f'SARIMA failed ({e}); using seasonal naive baseline.')\n",
    "    sarima_ok = False\n",
    "    # Seasonal naive: y_{t+h} = y_{t+h-12}\n",
    "    y_pred_sarima = pd.Series(\n",
    "        y_trainval.values[-12:len(y_test) if len(y_test) <= 12 else 12],\n",
    "        index=y_test.index[:12]\n",
    "    )\n",
    "\n",
    "# Predictions from regularised models\n",
    "y_pred_ridge = pd.Series(\n",
    "    gs_ridge.best_estimator_.predict(X_test),\n",
    "    index=y_test.index\n",
    ")\n",
    "y_pred_lasso = pd.Series(\n",
    "    gs_lasso.best_estimator_.predict(X_test),\n",
    "    index=y_test.index\n",
    ")\n",
    "y_pred_en = pd.Series(\n",
    "    gs_en.best_estimator_.predict(X_test),\n",
    "    index=y_test.index\n",
    ")\n",
    "\n",
    "# Evaluation helper\n",
    "def rmse(actual, predicted):\n",
    "    pred = np.asarray(predicted)[:len(actual)]\n",
    "    return np.sqrt(mean_squared_error(actual[:len(pred)], pred))\n",
    "\n",
    "def mae(actual, predicted):\n",
    "    pred = np.asarray(predicted)[:len(actual)]\n",
    "    return np.mean(np.abs(np.asarray(actual[:len(pred)]) - pred))\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['SARIMA(1,1,1)(1,1,1)_12', 'Ridge', 'LASSO', 'Elastic Net'],\n",
    "    'RMSE': [\n",
    "        rmse(y_test, y_pred_sarima) if sarima_ok else float('nan'),\n",
    "        rmse(y_test, y_pred_ridge),\n",
    "        rmse(y_test, y_pred_lasso),\n",
    "        rmse(y_test, y_pred_en),\n",
    "    ],\n",
    "    'MAE': [\n",
    "        mae(y_test, y_pred_sarima) if sarima_ok else float('nan'),\n",
    "        mae(y_test, y_pred_ridge),\n",
    "        mae(y_test, y_pred_lasso),\n",
    "        mae(y_test, y_pred_en),\n",
    "    ],\n",
    "})\n",
    "results['RMSE'] = results['RMSE'].round(1)\n",
    "results['MAE']  = results['MAE'].round(1)\n",
    "print('\\nTest-set evaluation:')\n",
    "print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Section 9: Forecast Comparison Plot\n",
    "# =============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 4))\n",
    "\n",
    "# Last 24 train+val obs for context\n",
    "context = y_trainval.iloc[-24:]\n",
    "ax.plot(context.index.astype(str), context.values,\n",
    "        color=UNO['lightgray'], lw=1.5, label='History')\n",
    "\n",
    "# Actuals\n",
    "ax.plot(y_test.index.astype(str), y_test.values,\n",
    "        color='black', lw=2, label='Actual', zorder=5)\n",
    "\n",
    "# Forecasts\n",
    "test_idx = y_test.index.astype(str)\n",
    "\n",
    "if sarima_ok:\n",
    "    sarima_vals = np.asarray(y_pred_sarima)[:len(y_test)]\n",
    "    ax.plot(test_idx[:len(sarima_vals)], sarima_vals,\n",
    "            color=UNO['gray'],  lw=1.5, ls='--', label='SARIMA')\n",
    "\n",
    "ax.plot(test_idx, y_pred_ridge.values,\n",
    "        color=UNO['blue'],  lw=1.5, ls='-.', label='Ridge')\n",
    "ax.plot(test_idx, y_pred_lasso.values,\n",
    "        color=UNO['red'],   lw=1.5, ls=':',  label='LASSO')\n",
    "ax.plot(test_idx, y_pred_en.values,\n",
    "        color=UNO['green'], lw=2.0,           label='Elastic Net')\n",
    "\n",
    "ax.set_title('Forecast Comparison: SARIMA vs. Regularised Models (Test Set)')\n",
    "ax.set_xlabel('Period')\n",
    "ax.set_ylabel('Retail Sales (Millions USD)')\n",
    "ax.legend(loc='upper left', fontsize=9)\n",
    "ax.xaxis.set_major_locator(mticker.MaxNLocator(8))\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "# Annotate RMSE\n",
    "for i, (model_name, color, pred) in enumerate([\n",
    "    ('Ridge',       UNO['blue'],  y_pred_ridge),\n",
    "    ('LASSO',       UNO['red'],   y_pred_lasso),\n",
    "    ('Elastic Net', UNO['green'], y_pred_en),\n",
    "]):\n",
    "    r = rmse(y_test, pred)\n",
    "    ax.annotate(f'{model_name}: RMSE={r:,.0f}',\n",
    "                xy=(0.99, 0.97 - i * 0.09),\n",
    "                xycoords='axes fraction',\n",
    "                ha='right', va='top',\n",
    "                fontsize=9, color=color)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{FIGURE_DIR}/lecture08_forecast_comparison.png',\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved lecture08_forecast_comparison.png')\n",
    "\n",
    "print('\\n=== Final Results ===')\n",
    "print(results.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
